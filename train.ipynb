{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from os.path import join as opj\n",
    "import cv2\n",
    "\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import models,transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, roc_curve\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "np.random.seed(123)\n",
    "torch.cuda.manual_seed_all(5)\n",
    "torch.backends.cudnn.deterministic=True\n",
    "torch.manual_seed(123)\n",
    "BATCH_SIZE = 64\n",
    "EMBEDDING_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CelebADataset(Dataset):\n",
    "    \n",
    "    def __init__(self, base_path, transform=None):\n",
    "        self.images_path = opj(base_path, \"images\")\n",
    "        self.names = []\n",
    "        self.labels = []\n",
    "        identity_list = opj(base_path, \"identity_CelebA.txt\")\n",
    "        \n",
    "        for l in open(identity_list):\n",
    "            name, label = l.split(sep=\" \")\n",
    "            self.names.append(name.replace('jpg','png'))\n",
    "            self.labels.append(int(label.replace(\"\\n\",\"\")))\n",
    "            \n",
    "        self.transform = transform\n",
    "        self.labels = torch.Tensor(self.labels).long()\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        img = cv2.imread(opj(self.images_path,self.names[idx]))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        #img = cv2.resize(img, (256,256))\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        return {\"image\":img, \"label\":label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x223be8ef7b0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = torch.Generator()\n",
    "g.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "    \n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CelebADataset(\".\\\\CelebA\", transform=transform)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = int(0.2 * len(dataset)) + 1\n",
    "\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, (train_size,test_size))\n",
    "train_loader = DataLoader(train_dataset,batch_size=BATCH_SIZE, shuffle=True,generator=g)\n",
    "test_loader = DataLoader(test_dataset,batch_size=BATCH_SIZE, shuffle=False,generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "acos_eps = 1e-6\n",
    "\n",
    "def ArcfaceLoss(y_pred,y_true):\n",
    "    \n",
    "    denominators = torch.sum(torch.exp(s*y_pred), dim=1)\n",
    "    denominators = denominators - torch.exp(torch.sum(y_true * y_pred * s, dim=1))\n",
    "    cos_thetas = torch.sum(y_true * y_pred, dim=1)\n",
    "    cos_thetas = torch.clamp(cos_thetas,-1+acos_eps, 1-acos_eps)\n",
    "    thetas = torch.acos(cos_thetas)\n",
    "    new_cos_thetas = s * torch.cos(thetas + m)\n",
    "    numerators = torch.exp(new_cos_thetas)\n",
    "    denominators = denominators + numerators\n",
    "    loss = -torch.mean(torch.log(numerators / denominators))\n",
    "    \n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Backbone(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Backbone,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 8, 3,1,1)\n",
    "        self.bn8 = nn.BatchNorm2d(8)\n",
    "        self.bn16 = nn.BatchNorm2d(16)\n",
    "        self.bn32 = nn.BatchNorm2d(32)\n",
    "        self.bn64 = nn.BatchNorm2d(64)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(8, 16, 3,1,1)\n",
    "        self.conv3 = nn.Conv2d(16,32,3,1,1)\n",
    "        self.conv4 = nn.Conv2d(32,64,3,1,1)\n",
    "        self.fc1 = nn.Linear(9152, 2048)\n",
    "        self.fc2 = nn.Linear(2048, EMBEDDING_SIZE)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.leaky_relu(self.conv1(x)))\n",
    "        x = self.bn8(x)\n",
    "        x = self.pool(F.leaky_relu(self.conv2(x)))\n",
    "        x = self.bn16(x)\n",
    "        x = self.pool(F.leaky_relu(self.conv3(x)))\n",
    "        x = self.bn32(x)\n",
    "        x = self.pool(F.leaky_relu(self.conv4(x)))\n",
    "        x = self.bn64(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        emb = F.normalize(x, p=2.0, dim=1)\n",
    "        \n",
    "        return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Backbone(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Backbone,self).__init__()\n",
    "        self.resnet = torchvision.models.resnet18(weights=None)\n",
    "        self.resnet.fc = nn.Sequential()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.resnet(x))\n",
    "        emb = F.normalize(x, p=2.0, dim=1)\n",
    "        \n",
    "        return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArcfaceNN(Backbone):\n",
    "    def __init__(self,n_classes):\n",
    "        super(ArcfaceNN,self).__init__()\n",
    "        self.n_classes = n_classes\n",
    "        self.fc = nn.Linear(EMBEDDING_SIZE, self.n_classes)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        emb = super(ArcfaceNN,self).forward(x)\n",
    "        \n",
    "        for W in self.fc.parameters():\n",
    "            W = F.normalize(W, p=2, dim=0)\n",
    "        \n",
    "        x = self.fc(emb)\n",
    "        \n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def make_emb(self,x):\n",
    "        return super(ArcfaceNN,self).forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = int(dataset.labels.max()) + 1\n",
    "ARCFACE_EPOCHS = 50\n",
    "s = 64.0\n",
    "m = 0.5\n",
    "arcface_model = ArcfaceNN(n_classes).to(device).train()\n",
    "lr = 0.0001\n",
    "criterion = ArcfaceLoss\n",
    "optimizer = optim.Adam(arcface_model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 499 of 2533\n",
      "batch 999 of 2533\n",
      "batch 1499 of 2533\n",
      "batch 1999 of 2533\n",
      "batch 2499 of 2533\n",
      "[0] loss: 26231.052734375\n",
      "batch 499 of 2533\n",
      "batch 999 of 2533\n",
      "batch 1499 of 2533\n",
      "batch 1999 of 2533\n",
      "batch 2499 of 2533\n",
      "[1] loss: 23529.451171875\n",
      "batch 499 of 2533\n",
      "batch 999 of 2533\n",
      "batch 1499 of 2533\n",
      "batch 1999 of 2533\n",
      "batch 2499 of 2533\n",
      "[2] loss: 21054.9921875\n",
      "batch 499 of 2533\n",
      "batch 999 of 2533\n",
      "batch 1499 of 2533\n",
      "batch 1999 of 2533\n",
      "batch 2499 of 2533\n",
      "[3] loss: 17742.369140625\n",
      "batch 499 of 2533\n",
      "batch 999 of 2533\n",
      "batch 1499 of 2533\n",
      "batch 1999 of 2533\n",
      "batch 2499 of 2533\n",
      "[4] loss: 14419.4189453125\n",
      "batch 499 of 2533\n",
      "batch 999 of 2533\n",
      "batch 1499 of 2533\n",
      "batch 1999 of 2533\n",
      "batch 2499 of 2533\n",
      "[5] loss: 11426.54296875\n",
      "batch 499 of 2533\n",
      "batch 999 of 2533\n",
      "batch 1499 of 2533\n",
      "batch 1999 of 2533\n",
      "batch 2499 of 2533\n",
      "[6] loss: 8864.9814453125\n",
      "batch 499 of 2533\n",
      "batch 999 of 2533\n",
      "batch 1499 of 2533\n",
      "batch 1999 of 2533\n",
      "batch 2499 of 2533\n",
      "[7] loss: 6798.6142578125\n",
      "batch 499 of 2533\n",
      "batch 999 of 2533\n",
      "batch 1499 of 2533\n",
      "batch 1999 of 2533\n",
      "batch 2499 of 2533\n",
      "[8] loss: 5127.58642578125\n",
      "batch 499 of 2533\n",
      "batch 999 of 2533\n",
      "batch 1499 of 2533\n",
      "batch 1999 of 2533\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "epoch = 0\n",
    "while(epoch <= ARCFACE_EPOCHS):\n",
    "    epoch_loss = 0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        if i % 500 == 499:\n",
    "            print(f\"batch {i} of {len(train_loader)}\")\n",
    "        image, label = data['image'],data['label']\n",
    "        image = image.to(device)\n",
    "        label = label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = arcface_model.forward(image)\n",
    "        label = F.one_hot(label,num_classes=n_classes)\n",
    "        \n",
    "        loss = criterion(y_pred,label) \n",
    "        epoch_loss +=loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    torch.save(arcface_model, f\".\\\\arcface_new_{epoch_loss}.pt\")\n",
    "    print(f'[{epoch}] loss: {epoch_loss}')\n",
    "    epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcface_model.fc = nn.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_dataset\n",
    "del train_loader\n",
    "del g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array([sample['label'] for sample in test_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = []\n",
    "arcface_model = arcface_model.to(device).eval()\n",
    "\n",
    "for data in test_loader:\n",
    "        image, labebl = data['image'],data['label']\n",
    "        image = image.to(device)\n",
    "        embs.extend(arcface_model.forward(image).detach().cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_class = labels[:, np.newaxis] != labels[np.newaxis, :]\n",
    "diff_class = torch.Tensor(diff_class).to(device).bool().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idc = torch.triu_indices(n_samples,n_samples,1,device=device)\n",
    "idc = idc[0] * n_samples + idc[1]\n",
    "diff_class = diff_class[idc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dists = euclidean_distances(embs,embs).flatten()\n",
    "dists_np = pdist(embs).astype('float16')\n",
    "dists = torch.Tensor(dists_np).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del embs\n",
    "del test_loader\n",
    "del test_dataset\n",
    "del labels\n",
    "del idc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_class_np = diff_class.cpu().numpy().astype('bool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(~diff_class_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.xlim(0.0,2)\n",
    "plt.hist(dists_np[~diff_class_np],alpha = 0.5,color=\"blue\",label=\"Positive pairs\",range=(0.01,2))\n",
    "plt.hist(dists_np[diff_class_np][:np.sum(~diff_class_np)],alpha = 0.5,color=\"red\",label=\"Negative pairs\") #what?\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_index = np.argsort(dists_np)\n",
    "diff_class_np = diff_class_np[sort_index]\n",
    "dists_np = dists_np[sort_index]\n",
    "del sort_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TP = np.sum(np.logical_and(preds == 1, y_true == 1))\n",
    "#TN = np.sum(np.logical_and(preds == 0, y_true == 0))\n",
    "#FP = np.sum(np.logical_and(preds == 1, y_true == 0))\n",
    "#FN = np.sum(np.logical_and(preds == 0, y_true == 1))\n",
    "#sort_index = np.argsort(distances)\n",
    "#y_true = y_true[sort_index]\n",
    "#distances = distances[sort_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_curve_my(y_true, distances):\n",
    "    threshes = []\n",
    "    fpr = []\n",
    "    tpr = []\n",
    "    \n",
    "    \n",
    "        \n",
    "    start_i = 0\n",
    "    end_i = 0\n",
    "    \n",
    "    preds = distances >= 0.0\n",
    "    TP = np.sum(y_true == 1)\n",
    "    TN = 0\n",
    "    FP = len(y_true) - TP\n",
    "    FN = 0\n",
    "    \n",
    "    TPFN = TP + FN\n",
    "    FPTN = FP + TN\n",
    "\n",
    "    \n",
    "    tpr.append(TP / TPFN)\n",
    "    fpr.append(FP/ FPTN)\n",
    "    \n",
    "    for thresh in np.arange(0.0,2.001,0.001):\n",
    "        while(distances[end_i] < thresh):\n",
    "            end_i +=1\n",
    "            if(end_i >= len(distances) -1):\n",
    "                end_i = len(distances) -1\n",
    "                break\n",
    "        \n",
    "        if(start_i == end_i):\n",
    "            continue\n",
    "        slc_true = y_true[start_i:end_i]\n",
    "        \n",
    "        \n",
    "        a_FN = np.sum(slc_true == 1)\n",
    "        a_TN = np.sum(slc_true == 0)\n",
    "        \n",
    "        TP -= a_FN\n",
    "        FP -= a_TN\n",
    "        \n",
    "        \n",
    "        tpr.append(TP / TPFN)\n",
    "        fpr.append(FP/ FPTN)\n",
    "        threshes.append(thresh)\n",
    "        \n",
    "        start_i = end_i\n",
    "        if(end_i >= len(distances) -1):\n",
    "            end_i = len(distances) -1\n",
    "    threshes = np.append(threshes,10.0)\n",
    "    return fpr,tpr,threshes\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mfpr,mtpr,thresh = roc_curve_my(diff_class_np,dists_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5))\n",
    "plt.xscale('log')\n",
    "plt.yticks(np.arange(0,1,0.05))\n",
    "plt.xlim(0.00005,1)\n",
    "plt.plot(mfpr,mtpr)\n",
    "plt.title(\"ROC curve\")\n",
    "plt.ylabel('True Positive Rate')  \n",
    "plt.xlabel('False Positive Rate')  \n",
    "plt.grid()\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_pt = np.argmin(np.linalg.norm(np.array([1.0, 0.0]) - np.vstack([mtpr,mfpr]).T,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5))\n",
    "plt.xscale('log')\n",
    "plt.yticks(np.arange(0,1,0.05))\n",
    "plt.xlim(0.00006,1)\n",
    "plt.plot(mfpr,mtpr)\n",
    "plt.scatter(mfpr[closest_pt],mtpr[closest_pt],c=\"red\")\n",
    "plt.title(\"ROC curve\")\n",
    "plt.ylabel('True Positive Rate')  \n",
    "plt.xlabel('False Positive Rate')  \n",
    "plt.grid()\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_thresh = thresh[closest_pt]\n",
    "y_preds = dists_np > best_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy score: \", accuracy_score(diff_class_np, y_preds))\n",
    "print(\"Best thresh: \", best_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inp = torch.rand(1, 3, 122, 122).to(device)\n",
    "traced_script_module = torch.jit.trace(arcface_model, inp)\n",
    "traced_script_module.save(\"traced_arcface_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
